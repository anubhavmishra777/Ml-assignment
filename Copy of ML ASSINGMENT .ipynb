{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11GIHVlXfzNz7IZ_WXyUbhMboVAxvPTkF","timestamp":1732209754617},{"file_id":"1HZXY3f42LDMya8hxzM1SN7XJdqq4NmpH","timestamp":1732209451635}],"authorship_tag":"ABX9TyP9fZOYABxNyUS61HxVGgU4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmizvrKRuaI2","executionInfo":{"status":"ok","timestamp":1732209428370,"user_tz":-330,"elapsed":10889,"user":{"displayName":"Shailesh Dwivedi","userId":"01351535275626828977"}},"outputId":"36823276-f1fd-47be-80d6-7dcfba3d8c49"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 rows:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","\n","Dataset shape:\n","(150, 4)\n","\n","Summary statistics:\n","       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","count         150.000000        150.000000         150.000000   \n","mean            5.843333          3.057333           3.758000   \n","std             0.828066          0.435866           1.765298   \n","min             4.300000          2.000000           1.000000   \n","25%             5.100000          2.800000           1.600000   \n","50%             5.800000          3.000000           4.350000   \n","75%             6.400000          3.300000           5.100000   \n","max             7.900000          4.400000           6.900000   \n","\n","       petal width (cm)  \n","count        150.000000  \n","mean           1.199333  \n","std            0.762238  \n","min            0.100000  \n","25%            0.300000  \n","50%            1.300000  \n","75%            1.800000  \n","max            2.500000  \n","\n","Number of samples in training set: 120\n","Number of samples in testing set: 30\n"]}],"source":["import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# 1. Dataset Exploration\n","iris = load_iris()\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","\n","print(\"First 5 rows:\")\n","print(iris_df.head())\n","\n","print(\"\\nDataset shape:\")\n","print(iris_df.shape)\n","\n","print(\"\\nSummary statistics:\")\n","print(iris_df.describe())\n","\n","# 2. Data Splitting (Using the first two features for simplicity)\n","X_train, X_test, y_train, y_test = train_test_split(iris.data[:, :2], iris.target, test_size=0.2, random_state=42)\n","\n","print(\"\\nNumber of samples in training set:\", len(X_train))\n","print(\"Number of samples in testing set:\", len(X_test))\n","\n"]}]}